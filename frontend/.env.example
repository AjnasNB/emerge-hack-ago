# LLM Provider Configuration
# Supported: openai | groq | azure | ollama
LLM_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Groq (alternative - very fast)
# GROQ_API_KEY=gsk_your-key-here
# GROQ_MODEL=llama-3.1-70b-versatile

# Azure OpenAI (alternative)
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_KEY=your-key
# AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini

# Ollama (local, alternative)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1
 